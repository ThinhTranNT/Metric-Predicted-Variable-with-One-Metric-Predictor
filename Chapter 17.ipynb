{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 17 - Metric Predicted Variable with One Metric Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [17.2 - Robust Linear Regression](#17.2---Robust-Linear-Regression)\n",
    "- [17.3 - Hierarchical Regression on Individuals within Groups](#17.3---Hierarchical-Regression-on-Individuals-within-Groups)\n",
    "- [17.4 - Quadratic Trend and Weighted Data](#17.4---Quadratic-Trend-and-Weighted-Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'theano' has no attribute 'compile' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# import numpy as np\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpm\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymc3/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplatform\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msemver\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\n\u001b[1;32m     25\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpymc3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;241m.\u001b[39mhandlers:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/theano/__init__.py:124\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msafe_asarray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _asarray\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprinting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pprint, pp\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscan_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (scan, \u001b[38;5;28mmap\u001b[39m, reduce, foldl, foldr, clone,\n\u001b[1;32m    125\u001b[0m                                 scan_checkpoints)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mupdates\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrderedUpdates\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# scan_module import above initializes tensor and scalar making these imports\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# redundant\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# import sparse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/theano/scan_module/__init__.py:41\u001b[0m\n\u001b[1;32m     38\u001b[0m __copyright__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(c) 2010, Universite de Montreal\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m __contact__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRazvan Pascanu <r.pascanu@gmail>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscan_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scan_opt\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscan_module\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scan\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscan_module\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscan_checkpoints\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scan_checkpoints\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/theano/scan_module/scan_opt.py:60\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor, scalar\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m opt, get_scalar_constant_value, Alloc, AllocEmpty\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gof\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/theano/tensor/__init__.py:8\u001b[0m\n\u001b[1;32m      4\u001b[0m __docformat__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestructuredtext en\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msubtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtype_other\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/theano/tensor/basic.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgof\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Apply, Constant, Op, Variable, ParamsType\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgof\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtype\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Generic\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscalar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m int32 \u001b[38;5;28;01mas\u001b[39;00m int32_t\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m elemwise\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (AsTensorError, TensorVariable,\n\u001b[1;32m     23\u001b[0m                                TensorConstant, TensorConstantSignature,\n\u001b[1;32m     24\u001b[0m                                _tensor_py_operators)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/theano/scalar/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m absolute_import, print_function, division\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic_scipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/theano/scalar/basic.py:656\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m shape_info\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# Register C code for ViewOp on Scalars.\u001b[39;00m\n\u001b[0;32m--> 656\u001b[0m theano\u001b[38;5;241m.\u001b[39mcompile\u001b[38;5;241m.\u001b[39mregister_view_op_c_code(\n\u001b[1;32m    657\u001b[0m     Scalar,\n\u001b[1;32m    658\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;124;03m    %(oname)s = %(iname)s;\u001b[39;00m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m,\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m get_scalar_type(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    665\u001b[0m int8 \u001b[38;5;241m=\u001b[39m get_scalar_type(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'theano' has no attribute 'compile' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from matplotlib import gridspec\n",
    "from IPython.display import Image\n",
    "import theano.tensor as tt\n",
    "\n",
    "# Loại bỏ cảnh báo FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Sử dụng %matplotlib inline để hiển thị biểu đồ ngay trong Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Sử dụng kiểu mặc định cho biểu đồ\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "# Định nghĩa màu sắc\n",
    "plot_color = '#87ceeb'\n",
    "\n",
    "# Định nghĩa thông số cho font\n",
    "font_dict = {'size': 16}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'watermark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwatermark\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwatermark\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-p pandas,numpy,pymc3,theano,matplotlib,seaborn,scipy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2432\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2430\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2431\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2432\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2435\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2436\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/magics/extension.py:33\u001b[0m, in \u001b[0;36mExtensionMagics.load_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_str:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UsageError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing module name.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39mextension_manager\u001b[38;5;241m.\u001b[39mload_extension(module_str)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malready loaded\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m extension is already loaded. To reload it, use:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m module_str)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/extensions.py:76\u001b[0m, in \u001b[0;36mExtensionManager.load_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load an IPython extension by its module name.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03mReturns the string \"already loaded\" if the extension is already loaded,\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"no load function\" if the module doesn't have a load_ipython_extension\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mfunction, or None if it succeeded.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_extension(module_str)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01min\u001b[39;00m BUILTINS_EXTS:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/extensions.py:91\u001b[0m, in \u001b[0;36mExtensionManager._load_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[0;32m---> 91\u001b[0m         mod \u001b[38;5;241m=\u001b[39m import_module(module_str)\n\u001b[1;32m     92\u001b[0m     mod \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[module_str]\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_load_ipython_extension(mod):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'watermark'"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p pandas,numpy,pymc3,theano,matplotlib,seaborn,scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid(trace, data, sd_h, sd_w, mean_h, mean_w):\n",
    "    \"\"\"This function creates plots like figures 17.3 and 17.4 in the book.\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(13,13))\n",
    "    \n",
    "    # Define gridspec\n",
    "    gs = gridspec.GridSpec(4, 6)\n",
    "    ax1 = plt.subplot(gs[:2,1:5])\n",
    "    ax2 = plt.subplot(gs[2,:2])\n",
    "    ax3 = plt.subplot(gs[2,2:4])\n",
    "    ax4 = plt.subplot(gs[2,4:6])\n",
    "    ax5 = plt.subplot(gs[3,:2])\n",
    "    ax6 = plt.subplot(gs[3,2:4])                     \n",
    "    ax7 = plt.subplot(gs[3,4:6])\n",
    "        \n",
    "    # Scatter plot of the observed data\n",
    "    ax1.scatter(data.height, data.weight, s=40, linewidths=1, facecolor='none', edgecolor='k', zorder=10)\n",
    "    ax1.set_xlabel('height', fontdict=f_dict)\n",
    "    ax1.set_ylabel('height', fontdict=f_dict)\n",
    "    ax1.set(xlim=(0,80), ylim=(-350,250))\n",
    "\n",
    "    # Convert parameters to original scale\n",
    "    beta0 = trace['beta0']*sd_w+mean_w-trace['beta1']*mean_h*sd_w/sd_h\n",
    "    beta1 = trace['beta1']*(sd_w/sd_h)\n",
    "    sigma = trace['sigma']*sd_w\n",
    "    B = pd.DataFrame(np.c_[beta0, beta1], columns=['beta0', 'beta1'])\n",
    "       \n",
    "    # Credible regression lines from posterior\n",
    "    hpd_interval = np.round(pm.hpd(B.values, alpha=0.05), decimals=3)\n",
    "    B_hpd = B[B.beta0.between(*hpd_interval[0,:]) & B.beta1.between(*hpd_interval[1,:])] \n",
    "    xrange = np.arange(0, data.height.max()*1.05)\n",
    "    for i in np.random.randint(0, len(B_hpd), 30):\n",
    "        ax1.plot(xrange, B_hpd.iloc[i,0]+B_hpd.iloc[i,1]*xrange, c=color, alpha=.6, zorder=0)    \n",
    "        \n",
    "    # Intercept\n",
    "    pm.plot_posterior(beta0, point_estimate='mode', ax=ax2, color=color)\n",
    "    ax2.set_xlabel(r'$\\beta_0$', fontdict=f_dict)\n",
    "    ax2.set_title('Intercept', fontdict={'weight':'bold'})\n",
    "\n",
    "    # Slope\n",
    "    pm.plot_posterior(beta1, point_estimate='mode', ax=ax3, color=color, ref_val=0)\n",
    "    ax3.set_xlabel(r'$\\beta_1$', fontdict=f_dict)\n",
    "    ax3.set_title('Slope', fontdict={'weight':'bold'})\n",
    "    \n",
    "    # Scatter plot beta1, beta0\n",
    "    ax4.scatter(beta1, beta0, edgecolor=color, facecolor='none', alpha=.6)\n",
    "    ax4.set_xlabel(r'$\\beta_1$', fontdict=f_dict)\n",
    "    ax4.set_ylabel(r'$\\beta_0$', fontdict=f_dict)\n",
    "    \n",
    "    # Scale\n",
    "    pm.plot_posterior(sigma, point_estimate='mode', ax=ax5, color=color)\n",
    "    ax5.set_xlabel(r'$\\sigma$', fontdict=f_dict)\n",
    "    ax5.set_title('Scale', fontdict={'weight':'bold'})\n",
    "\n",
    "    # Normality\n",
    "    pm.plot_posterior(np.log10(trace['nu']), point_estimate='mode', ax=ax6, color=color)\n",
    "    ax6.set_xlabel(r'log10($\\nu$)', fontdict=f_dict)\n",
    "    ax6.set_title('Normality', fontdict={'weight':'bold'})\n",
    "    \n",
    "    # Scatter plot normality, sigma\n",
    "    ax7.scatter(np.log10(trace['nu']), sigma,\n",
    "                edgecolor=color, facecolor='none', alpha=.6)\n",
    "    ax7.set_xlabel(r'log10($\\nu$)', fontdict=f_dict)\n",
    "    ax7.set_ylabel(r'$\\sigma$', fontdict=f_dict)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return(plt.gcf());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cred_lines(dist, x, sd_x, sd_y, mean_x, mean_y, ax):\n",
    "    \"\"\"This function plots credibility lines.\"\"\"\n",
    "    # Convert parameters to original scale\n",
    "    beta0 = dist[:,0]*sd_y+mean_y-dist[:,1]*mean_x*sd_y/sd_x\n",
    "    beta1 = dist[:,1]*(sd_y/sd_x)\n",
    "    B = pd.DataFrame(np.c_[beta0, beta1], columns=['beta0', 'beta1'])\n",
    "\n",
    "    # Credible regression lines from posterior\n",
    "    hpd_interval = np.round(pm.hpd(B.values, alpha=0.05), decimals=3)\n",
    "    hpd_interval = pm.hpd(B.values, alpha=0.05)\n",
    "    B_hpd = B[B.beta0.between(*hpd_interval[0,:]) & B.beta1.between(*hpd_interval[1,:])] \n",
    "    xrange = np.arange(x.min()*.95, x.max()*1.05)\n",
    "    for i in np.random.randint(0, len(B_hpd), 30):\n",
    "        ax.plot(xrange, B_hpd.iloc[i,0]+B_hpd.iloc[i,1]*xrange, c=color, alpha=.6, zorder=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quad_credlines(dist, x, sd_x, sd_y, mean_x, mean_y, ax):\n",
    "    \"\"\"This function plots quadratic credibility lines.\"\"\"\n",
    "    # Convert parameters to original scale\n",
    "    beta0 = dist[:,0]*sd_y+mean_y-dist[:,1]*mean_x*sd_y/sd_x + dist[:,2]*mean_x**2*sd_y/sd_x**2\n",
    "    beta1 = dist[:,1]*sd_y/sd_x - 2*dist[:,2]*mean_x*sd_y/sd_x**2\n",
    "    beta2 = dist[:,2]*sd_y/sd_x**2\n",
    "    B = pd.DataFrame(np.c_[beta0, beta1, beta2], columns=['beta0', 'beta1', 'beta2'])\n",
    "\n",
    "    # Credible regression lines from posterior\n",
    "    hpd_interval = pm.hpd(B.values, alpha=0.05)\n",
    "    B_hpd = B[B.beta0.between(*hpd_interval[0,:]) & B.beta1.between(*hpd_interval[1,:]) & B.beta2.between(*hpd_interval[2,:])] \n",
    "    xrange = np.arange(x.min()-1, x.max()+2)\n",
    "    for i in np.random.randint(0, len(B_hpd), 30):\n",
    "        ax.plot(xrange, B_hpd.iloc[i,0]+B_hpd.iloc[i,1]*xrange+B_hpd.iloc[i,2]*xrange**2, c=color, alpha=.6, zorder=0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.2 - Robust Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model (Kruschke, 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('images/fig17_2.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n30 = pd.read_csv('data/HtWtData30.csv')\n",
    "df_n30.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n30.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "sd_h = df_n30.height.std()\n",
    "mean_h = df_n30.height.mean()\n",
    "zheight = (df_n30.height - mean_h)/sd_h\n",
    "\n",
    "sd_w = df_n30.weight.std()\n",
    "mean_w = df_n30.weight.mean()\n",
    "zy = (df_n30.weight - mean_w)/sd_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    \n",
    "    beta0 = pm.Normal('beta0', mu=0, tau=1/10**2)\n",
    "    beta1 = pm.Normal('beta1', mu=0, tau=1/10**2)\n",
    "    mu =  beta0 + beta1*zheight.ravel()\n",
    "    \n",
    "    sigma = pm.Uniform('sigma', 10**-3, 10**3)\n",
    "    nu = pm.Exponential('nu', 1/29.)\n",
    "    \n",
    "    likelihood = pm.StudentT('likelihood', nu, mu=mu, sd=sigma, observed=zy.ravel())\n",
    "\n",
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pm.sample(3000, cores=4, nuts_kwargs={'target_accept': 0.95})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 17.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(trace, df_n30, sd_h, sd_w, mean_h, mean_w);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n300 = pd.read_csv('data/HtWtData300.csv')\n",
    "df_n300.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "sd_h2 = df_n300.height.std()\n",
    "mean_h2 = df_n300.height.mean()\n",
    "zheight2 = (df_n300.height - mean_h2)/sd_h2\n",
    "\n",
    "sd_w2 = df_n300.weight.std()\n",
    "mean_w2 = df_n300.weight.mean()\n",
    "zy2 = (df_n300.weight - mean_w2)/sd_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model2:\n",
    "    \n",
    "    beta0 = pm.Normal('beta0', mu=0, tau=1/10**2)\n",
    "    beta1 = pm.Normal('beta1', mu=0, tau=1/10**2)\n",
    "    mu =  beta0 + beta1*zheight2.ravel()\n",
    "    \n",
    "    sigma = pm.Uniform('sigma', 10**-3, 10**3)\n",
    "    nu = pm.Exponential('nu', 1/29.)\n",
    "    \n",
    "    likelihood = pm.StudentT('likelihood', nu, mu=mu, sd=sigma, observed=zy2.ravel())  \n",
    "\n",
    "pm.model_to_graphviz(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model2:\n",
    "    trace2 = pm.sample(3000, cores=4, nuts_kwargs={'target_accept': 0.95})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 17.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = plot_grid(trace2, df_n300, sd_h2, sd_w2, mean_h2, mean_w2)\n",
    "grid.axes[0].set_xlim(50,80)\n",
    "grid.axes[0].set_ylim(0,400);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.3 - Hierarchical Regression on Individuals within Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model (Kruschke, 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('images/fig17_6.png', width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HRegr = pd.read_csv('data/HierLinRegressData.csv')\n",
    "df_HRegr.Subj = df_HRegr.Subj.astype('category')\n",
    "df_HRegr.Subj = df_HRegr.Subj.cat.as_ordered()\n",
    "df_HRegr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HRegr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_idx = df_HRegr.Subj.cat.codes.values\n",
    "subj_codes = df_HRegr.Subj.cat.categories\n",
    "n_subj = len(subj_codes)\n",
    "\n",
    "print('Number of groups: {}'.format(n_subj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "sd_x3 = df_HRegr.X.std()\n",
    "mean_x3 = df_HRegr.X.mean()\n",
    "zx3 = (df_HRegr.X - mean_x3)/sd_x3\n",
    "\n",
    "sd_y3 = df_HRegr.Y.std()\n",
    "mean_y3 = df_HRegr.Y.mean()\n",
    "zy3 = (df_HRegr.Y - mean_y3)/sd_y3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "Reparameterization of hierarchical models generally results in much more efficient and faster sampling.  \n",
    "See http://twiecki.github.io/blog/2017/02/08/bayesian-hierchical-non-centered/ and  \n",
    "http://pymc3.readthedocs.io/en/latest/notebooks/Diagnosing_biased_Inference_with_Divergences.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model3:\n",
    "    \n",
    "    beta0 = pm.Normal('beta0', mu=0, tau=1/10**2)\n",
    "    beta1 = pm.Normal('beta1', mu=0, tau=1/10**2)\n",
    "    sigma0 = pm.Uniform('sigma0', 10**-3, 10**3)\n",
    "    sigma1 = pm.Uniform('sigma1', 10**-3, 10**3)\n",
    "    \n",
    "    # The below parameterization resulted in a lot of divergences.\n",
    "    #beta0_s = pm.Normal('beta0_s', mu=beta0, sd=sigma0, shape=n_subj)\n",
    "    #beta1_s = pm.Normal('beta1_s', mu=beta1, sd=sigma1, shape=n_subj)\n",
    "    \n",
    "    beta0_s_offset = pm.Normal('beta0_s_offset', mu=0, sd=1, shape=n_subj)\n",
    "    beta0_s = pm.Deterministic('beta0_s', beta0 + beta0_s_offset * sigma0)\n",
    "    \n",
    "    beta1_s_offset = pm.Normal('beta1_s_offset', mu=0, sd=1, shape=n_subj)\n",
    "    beta1_s = pm.Deterministic('beta1_s', beta1 + beta1_s_offset * sigma1)\n",
    "        \n",
    "    mu =  beta0_s[subj_idx] + beta1_s[subj_idx] * zx3\n",
    "    \n",
    "    sigma = pm.Uniform('sigma', 10**-3, 10**3)\n",
    "    nu = pm.Exponential('nu', 1/29.)\n",
    "    \n",
    "    likelihood = pm.StudentT('likelihood', nu, mu=mu, sd=sigma, observed=zy3)  \n",
    "\n",
    "pm.model_to_graphviz(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model3:\n",
    "    trace3 = pm.sample(3000, cores=4, nuts_kwargs={'target_accept': 0.95})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace3, ['beta0', 'beta1', 'sigma0', 'sigma1', 'sigma', 'nu']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 17.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "ax = plt.gca()\n",
    "\n",
    "df_HRegr.groupby('Subj').apply(lambda group: ax.plot(group.X, group.Y, 'k-o', lw=1, markersize=5, alpha=.4))\n",
    "ax.set(xlabel='X', ylabel='Y', ylim=(40,275), title='All Units');\n",
    "\n",
    "plot_cred_lines(np.c_[trace3['beta0'], trace3['beta1']], df_HRegr.X, sd_x3, sd_y3, mean_x3, mean_y3, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = sns.FacetGrid(df_HRegr, col='Subj', col_wrap=5, ylim=(50,250), height=2)\n",
    "fg.map(plt.scatter, 'X', 'Y', color='k', s=40)\n",
    "\n",
    "for i, ax in enumerate(fg.axes):\n",
    "    plot_cred_lines(np.c_[trace3['beta0_s'][:,i], trace3['beta1_s'][:,i]],\n",
    "                    df_HRegr.X, sd_x3, sd_y3, mean_x3, mean_y3, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.4 - Quadratic Trend and Weighted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income = pd.read_csv('data/IncomeFamszState3yr.csv', skiprows=1, dtype={'State':'category'})\n",
    "df_income.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_idx = df_income.State.cat.codes.values\n",
    "state_codes = df_income.State.cat.categories\n",
    "n_states = len(state_codes)\n",
    "\n",
    "print('Number of states: {}'.format(n_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fs = df_income.FamilySize.mean()\n",
    "sd_fs = df_income.FamilySize.std()\n",
    "z_fs = (df_income.FamilySize - mean_fs)/sd_fs\n",
    "\n",
    "mean_income = df_income.MedianIncome.mean()\n",
    "sd_income = df_income.MedianIncome.std()\n",
    "z_income = (df_income.MedianIncome - mean_income)/sd_income\n",
    "\n",
    "mean_error = df_income.SampErr.mean()\n",
    "z_error = df_income.SampErr / mean_error\n",
    "\n",
    "# There are fewer large-sized families than small-sized families, making the medians for income\n",
    "# for the former group noisier. We can modulate the noise parameter with the margin of error. \n",
    "plt.figure(figsize=(8,6))\n",
    "sns.swarmplot(x='FamilySize', y='SampErr', data=df_income)\n",
    "plt.title('Margin of Error per FamilySize');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model4:\n",
    "       \n",
    "    beta0 = pm.Normal('beta0', mu=0, tau=1/10**2)\n",
    "    beta1 = pm.Normal('beta1', mu=0, tau=1/10**2)\n",
    "    beta2 = pm.Normal('beta2', mu=0, tau=1/10**2)\n",
    "    \n",
    "    sigma0 = pm.Uniform('sigma0', 10**-3, 10**3)\n",
    "    sigma1 = pm.Uniform('sigma1', 10**-3, 10**3)\n",
    "    sigma2 = pm.Uniform('sigma2', 10**-3, 10**3)\n",
    "        \n",
    "    beta0_s = pm.Normal('beta0_s', mu=beta0, sd=sigma0, shape=n_states)\n",
    "    beta1_s = pm.Normal('beta1_s', mu=beta1, sd=sigma1, shape=n_states)\n",
    "    beta2_s = pm.Normal('beta2_s', mu=beta2, sd=sigma2, shape=n_states)\n",
    "    \n",
    "    mu =  beta0_s[state_idx] + beta1_s[state_idx] * z_fs + beta2_s[state_idx] * z_fs**2\n",
    "    \n",
    "    nu = pm.Exponential('nu', 1/29.)\n",
    "    sigma = pm.Uniform('sigma', 10**-3, 10**3)\n",
    "    \n",
    "    # Modulate the noise parameter with the margin of error.\n",
    "    w_sigma = tt.as_tensor(z_error)*sigma\n",
    "        \n",
    "    likelihood = pm.StudentT('likelihood', nu=nu, mu=mu, sd=w_sigma, observed=z_income)\n",
    "\n",
    "pm.model_to_graphviz(model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model4:\n",
    "    trace4 = pm.sample(3000, cores=4, nuts_kwargs={'target_accept': 0.95})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 17.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df_income.groupby('State').apply(lambda group: ax.plot(group.FamilySize,\n",
    "                                                       group.MedianIncome,\n",
    "                                                       'k-o', lw=1, markersize=5, alpha=.4))\n",
    "ax.set(xlabel='FamilySize', ylabel='MedianIncome', xlim=(1,8), title='All Units');\n",
    "\n",
    "plot_quad_credlines(np.c_[trace4['beta0'], trace4['beta1'], trace4['beta2']],\n",
    "                    df_income.FamilySize, sd_fs, sd_income, mean_fs, mean_income, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The book shows the data for the first 25 States.\n",
    "df_income_subset = df_income[df_income.State.isin(df_income.State.cat.categories[:25])]\n",
    "df_income_subset.State.cat.remove_unused_categories(inplace=True)\n",
    "\n",
    "fg = sns.FacetGrid(df_income_subset, col='State', col_wrap=5)\n",
    "fg.map(plt.scatter, 'FamilySize', 'MedianIncome', color='k', s=40);\n",
    "\n",
    "for i, ax in enumerate(fg.axes):\n",
    "    plot_quad_credlines(np.c_[trace4['beta0_s'][:,i], trace4['beta1_s'][:,i], trace4['beta2_s'][:,i]],\n",
    "                        df_income_subset.FamilySize, sd_fs, sd_income, mean_fs, mean_income, ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
